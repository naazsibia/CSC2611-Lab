{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.\n",
    "Download the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/naazsibia/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "from nltk.corpus import brown\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.\n",
    "Extract the 5000 most common English words (denoted by W ) based on unigram\n",
    "frequencies in the Brown corpus. Report the 5 most and least common words you have found\n",
    "in the 5000 words. Update W by adding n words where n is the set of words in Table 1\n",
    "of RG65 that were not included in the top 5000 words from the Brown corpus. Denote the\n",
    "total number of words in W as |W |."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most common words are ['the', ',', '.', 'of', 'and']\n",
      "The 5 least common words are ['cheek', 'awake', 'pursue', 'peered', 'crawled']\n"
     ]
    }
   ],
   "source": [
    "words_lower = [word.lower() for word in brown.words()] # ignore case\n",
    "fdist = FreqDist(words_lower)\n",
    "top5000 = fdist.most_common(5000)\n",
    "top5 = [word[0] for word in top5000[:5]]\n",
    "least5 = [word[0] for word in top5000[-5:]]\n",
    "print(\"The 5 most common words are\", top5)\n",
    "print(\"The 5 least common words are\", least5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = top5000.copy()\n",
    "\n",
    "# Words from the Brown corpus\n",
    "words = [\n",
    "    \"cord\", \"rooster\", \"noon\", \"fruit\", \"autograph\", \"automobile\", \"mound\", \"grin\", \"asylum\",\n",
    "    \"asylum\", \"graveyard\", \"glass\", \"boy\", \"cushion\", \"monk\", \"asylum\", \"coast\", \"grin\", \n",
    "    \"shore\", \"monk\", \"boy\", \"automobile\", \"mound\", \"lad\", \"forest\", \"food\", \"cemetery\", \n",
    "    \"shore\", \"bird\", \"coast\", \"furnace\", \"crane\", \"smile\", \"voyage\", \"string\", \"furnace\", \n",
    "    \"shore\", \"wizard\", \"stove\", \"implement\", \"fruit\", \"monk\", \"madhouse\", \"magician\", \n",
    "    \"rooster\", \"jewel\", \"slave\", \"cemetery\", \"forest\", \"lad\", \"woodland\", \"oracle\", \"sage\", \n",
    "    \"cushion\", \"shore\", \"wizard\", \"graveyard\", \"rooster\", \"woodland\", \"voyage\", \"woodland\", \n",
    "    \"hill\", \"implement\", \"hill\", \"car\", \"cemetery\", \"glass\", \"magician\", \"crane\", \"brother\", \n",
    "    \"sage\", \"oracle\", \"bird\", \"bird\", \"food\", \"brother\", \"asylum\", \"furnace\", \"magician\", \n",
    "    \"hill\", \"cord\", \"glass\", \"grin\", \"serf\", \"journey\", \"autograph\", \"coast\", \"forest\", \n",
    "    \"implement\", \"cock\", \"boy\", \"cushion\", \"cemetery\", \"automobile\", \"midday\", \"gem\", \n",
    "    \"woodland\", \"journey\", \"mound\", \"jewel\", \"oracle\", \"implement\", \"lad\", \"wizard\", \"sage\", \n",
    "    \"crane\", \"cock\", \"fruit\", \"monk\", \"madhouse\", \"stove\", \"wizard\", \"mound\", \"string\", \n",
    "    \"tumbler\", \"smile\", \"slave\", \"voyage\", \"signature\", \"shore\", \"woodland\", \"tool\", \n",
    "    \"rooster\", \"lad\", \"pillow\", \"graveyard\", \"car\", \"noon\", \"jewel\"]\n",
    "\n",
    "fdist = FreqDist(words)\n",
    "words_freq = list(fdist.items())\n",
    "existing_words = set([word[0] for word in W])\n",
    "\n",
    "# Trying not to add duplicates\n",
    "for word in words_freq:\n",
    "    if word[0] not in existing_words:\n",
    "        W.append(word)\n",
    "W = sorted(W, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|W| = 5031 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "Construct a word-context vector model (denoted by M1) by collecting bigram counts\n",
    "for words in W . The output should be a |W|×|W | matrix (consider using sparse matrices\n",
    "for better efficiency), where each row is a word in W , and each column is a context in W\n",
    "that precedes row words in sentences. For example, if the phrase taxi driver appears 5 times\n",
    "in the entire corpus, then row taxi and column driver should have a value of 5 in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = dok_matrix((len(W), len(W)), dtype=int) # sparce matrix\n",
    "W_words = [word[0] for word in W]\n",
    "word_to_index = {word: index for index, word in enumerate(W_words)}\n",
    "prev_word = None\n",
    "for word in brown.words():\n",
    "    if prev_word in word_to_index and word in word_to_index:\n",
    "        i = word_to_index[prev_word]\n",
    "        j = word_to_index[word]\n",
    "        M1[i, j] += 1\n",
    "    prev_word = word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "Compute positive pointwise mutual information on M1. Denote this model as M1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix # compressed sparse row - faster operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = M1.tocsr()\n",
    "word_probs = np.array(M1.sum(axis=1)).flatten() / M1.sum()\n",
    "bigram_probs = M1 / M1.sum()\n",
    "\n",
    "M1_coo = M1.tocoo() # coordinate format fast format for constructing sparse matrices\n",
    "\n",
    "pmi_values = []\n",
    "for i, j, val in zip(M1_coo.row, M1_coo.col, M1_coo.data):\n",
    "    joint_prob = val / M1.sum()\n",
    "    # 1e-10 added to prevent division by zero\n",
    "    pmi = np.log2(joint_prob / (word_probs[i] * word_probs[j] + 1e-10) + 1e-10)\n",
    "    pmi_values.append(pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_matrix = csr_matrix((pmi_values, (M1_coo.row, M1_coo.col)), shape = M1_coo.shape)\n",
    "\n",
    "# convert to dense format for the next operation\n",
    "pmi_dense = pmi_matrix.toarray()\n",
    "\n",
    "# replace negative values because positive pmi\n",
    "ppmi_matrix = np.maximum(pmi_dense, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a latent semantic model (denoted by M 2) by applying principal components analysis to M1+. The output should return 3 matrices, with different truncated dimenions at 10 (or a |W |×10 matrix, denoted by M 210), 100 (M 2100), and 300 (M 2300)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# create PCA instances for 10, 100, and 300 dimensions\n",
    "pca_10 = PCA(n_components=10)\n",
    "pca_100 = PCA(n_components=100)\n",
    "pca_300 = PCA(n_components=300)\n",
    "\n",
    "# Apply PCA to the PPMI matrix\n",
    "M_210 = pca_10.fit_transform(ppmi_matrix)\n",
    "M_2100 = pca_100.fit_transform(ppmi_matrix)\n",
    "M_2300 = pca_300.fit_transform(ppmi_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6.\n",
    "Find all pairs of words in Table 1 of RG65 that are also available in W . Denote these pairs as P . Record the human-judged similarities of these word pairs from the table\n",
    "and denote similarity values as S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs_with_scores = {\n",
    "    (\"cord\", \"smile\"): 0.02,\n",
    "    (\"rooster\", \"voyage\"): 0.04,\n",
    "    (\"noon\", \"string\"): 0.04,\n",
    "    (\"fruit\", \"furnace\"): 0.05,\n",
    "    (\"autograph\", \"shore\"): 0.06,\n",
    "    (\"automobile\", \"wizard\"): 0.11,\n",
    "    (\"mound\", \"stove\"): 0.14,\n",
    "    (\"grin\", \"implement\"): 0.18,\n",
    "    (\"asylum\", \"fruit\"): 0.19,\n",
    "    (\"asylum\", \"monk\"): 0.39,\n",
    "    (\"graveyard\", \"madhouse\"): 0.42,\n",
    "    (\"glass\", \"magician\"): 0.44,\n",
    "    (\"boy\", \"rooster\"): 0.44,\n",
    "    (\"cushion\", \"jewel\"): 0.45,\n",
    "    (\"monk\", \"slave\"): 0.57,\n",
    "    (\"asylum\", \"cemetery\"): 0.79,\n",
    "    (\"coast\", \"forest\"): 0.88,\n",
    "    (\"grin\", \"lad\"): 0.88,\n",
    "    (\"shore\", \"woodland\"): 0.90,\n",
    "    (\"monk\", \"oracle\"): 0.91,\n",
    "    (\"boy\", \"sage\"): 0.96,\n",
    "    (\"automobile\", \"cushion\"): 0.97,\n",
    "    (\"mound\", \"shore\"): 0.97,\n",
    "    (\"lad\", \"wizard\"): 0.99,\n",
    "    (\"forest\", \"graveyard\"): 1.00,\n",
    "    (\"food\", \"rooster\"): 1.09,\n",
    "    (\"cemetery\", \"woodland\"): 1.18,\n",
    "    (\"shore\", \"voyage\"): 1.22,\n",
    "    (\"bird\", \"woodland\"): 1.24,\n",
    "    (\"coast\", \"hill\"): 1.26,\n",
    "    (\"furnace\", \"implement\"): 1.37,\n",
    "    (\"crane\", \"rooster\"): 1.41,\n",
    "    (\"hill\", \"woodland\"): 1.48,\n",
    "    (\"car\", \"journey\"): 1.55,\n",
    "    (\"cemetery\", \"mound\"): 1.69,\n",
    "    (\"glass\", \"jewel\"): 1.78,\n",
    "    (\"magician\", \"oracle\"): 1.82,\n",
    "    (\"crane\", \"implement\"): 2.37,\n",
    "    (\"brother\", \"lad\"): 2.41,\n",
    "    (\"sage\", \"wizard\"): 2.46,\n",
    "    (\"oracle\", \"sage\"): 2.61,\n",
    "    (\"bird\", \"crane\"): 2.63,\n",
    "    (\"bird\", \"cock\"): 2.63,\n",
    "    (\"food\", \"fruit\"): 2.69,\n",
    "    (\"brother\", \"monk\"): 2.74,\n",
    "    (\"asylum\", \"madhouse\"): 3.04,\n",
    "    (\"furnace\", \"stove\"): 3.11,\n",
    "    (\"magician\", \"wizard\"): 3.21,\n",
    "    (\"hill\", \"mound\"): 3.29,\n",
    "    (\"cord\", \"string\"): 3.41,\n",
    "    (\"glass\", \"tumbler\"): 3.45,\n",
    "    (\"grin\", \"smile\"): 3.46,\n",
    "    (\"serf\", \"slave\"): 3.46,\n",
    "    (\"journey\", \"voyage\"): 3.58,\n",
    "    (\"autograph\", \"signature\"): 3.59,\n",
    "    (\"coast\", \"shore\"): 3.60,\n",
    "    (\"forest\", \"woodland\"): 3.65,\n",
    "    (\"implement\", \"tool\"): 3.66,\n",
    "    (\"cock\", \"rooster\"): 3.68,\n",
    "    (\"boy\", \"lad\"): 3.82,\n",
    "    (\"cushion\", \"pillow\"): 3.84,\n",
    "    (\"cemetry\", \"graveyard\"): 3.88,\n",
    "    (\"automobile\", \"car\"): 3.92,\n",
    "    (\"midday\", \"noon\"): 3.94,\n",
    "    (\"gem\", \"jewel\"): 3.94}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cord', 'smile'), ('rooster', 'voyage'), ('noon', 'string'), ('fruit', 'furnace'), ('autograph', 'shore'), ('automobile', 'wizard'), ('mound', 'stove'), ('grin', 'implement'), ('asylum', 'fruit'), ('asylum', 'monk'), ('graveyard', 'madhouse'), ('glass', 'magician'), ('boy', 'rooster'), ('cushion', 'jewel'), ('monk', 'slave'), ('asylum', 'cemetery'), ('coast', 'forest'), ('grin', 'lad'), ('shore', 'woodland'), ('monk', 'oracle'), ('boy', 'sage'), ('automobile', 'cushion'), ('mound', 'shore'), ('lad', 'wizard'), ('forest', 'graveyard'), ('food', 'rooster'), ('cemetery', 'woodland'), ('shore', 'voyage'), ('bird', 'woodland'), ('coast', 'hill'), ('furnace', 'implement'), ('crane', 'rooster'), ('hill', 'woodland'), ('car', 'journey'), ('cemetery', 'mound'), ('glass', 'jewel'), ('magician', 'oracle'), ('crane', 'implement'), ('brother', 'lad'), ('sage', 'wizard'), ('oracle', 'sage'), ('bird', 'crane'), ('bird', 'cock'), ('food', 'fruit'), ('brother', 'monk'), ('asylum', 'madhouse'), ('furnace', 'stove'), ('magician', 'wizard'), ('hill', 'mound'), ('cord', 'string'), ('glass', 'tumbler'), ('grin', 'smile'), ('serf', 'slave'), ('journey', 'voyage'), ('autograph', 'signature'), ('coast', 'shore'), ('forest', 'woodland'), ('implement', 'tool'), ('cock', 'rooster'), ('boy', 'lad'), ('cushion', 'pillow'), ('automobile', 'car'), ('midday', 'noon'), ('gem', 'jewel')]\n",
      "[0.02, 0.04, 0.04, 0.05, 0.06, 0.11, 0.14, 0.18, 0.19, 0.39, 0.42, 0.44, 0.44, 0.45, 0.57, 0.79, 0.88, 0.88, 0.9, 0.91, 0.96, 0.97, 0.97, 0.99, 1.0, 1.09, 1.18, 1.22, 1.24, 1.26, 1.37, 1.41, 1.48, 1.55, 1.69, 1.78, 1.82, 2.37, 2.41, 2.46, 2.61, 2.63, 2.63, 2.69, 2.74, 3.04, 3.11, 3.21, 3.29, 3.41, 3.45, 3.46, 3.46, 3.58, 3.59, 3.6, 3.65, 3.66, 3.68, 3.82, 3.84, 3.92, 3.94, 3.94]\n"
     ]
    }
   ],
   "source": [
    "P = []  # list to store pairs of words that are in W\n",
    "S = []  # list to store the human-judged similarity values of the word pairs\n",
    "\n",
    "for pair, similarity in word_pairs_with_scores.items():\n",
    "    word1, word2 = pair\n",
    "    if word1 in W_words and word2 in W_words:\n",
    "        P.append(pair)\n",
    "        S.append(similarity)\n",
    "\n",
    "print(P)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.\n",
    "Perform the following calculations on each of these models M 1, M1+, M_210, M_2100, M_2300, separately: Calculate cosine similarity between each pair of words in P , based on the\n",
    "constructed word vectors. Record model-predicted similarities: SM_1, SM_210 , SM_2100 , SM_2300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarities(model, pairs, word_list):\n",
    "    similarities = []\n",
    "    for pair in pairs:\n",
    "        idx1 = word_list.index(pair[0])\n",
    "        idx2 = word_list.index(pair[1])\n",
    "        \n",
    "        vec1 = model[idx1].reshape(1, -1)  # reshape to make it 2D for cosine_similarity\n",
    "        vec2 = model[idx2].reshape(1, -1)\n",
    "        \n",
    "        similarity = cosine_similarity(vec1, vec2)[0][0]\n",
    "        similarities.append(similarity)\n",
    "    return similarities\n",
    "\n",
    "# For each model, compute similarities\n",
    "SM_1 = calculate_similarities(M1, P, W_words)\n",
    "SM_1_plus = calculate_similarities(ppmi_matrix, P, W_words)\n",
    "SM_210 = calculate_similarities(M_210, P, W_words)\n",
    "SM_2100 = calculate_similarities(M_2100, P, W_words)\n",
    "SM_2300 = calculate_similarities(M_2300, P, W_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.\n",
    "Report Pearson correlation between S and each of the model-predicted similarities. Create a GitHub repository that implements all of your analyses; you will need this repo for\n",
    "the next lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with M_1: 0.14360014298240253\n",
      "Correlation with M1+: 0.2421342509950241\n",
      "Correlation with M_210: 0.167807592945941\n",
      "Correlation with M_2100: 0.3328363250230704\n",
      "Correlation with M_2300: 0.3515146719359085\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "correlation_M_1 = pearsonr(S, SM_1)[0]\n",
    "correlation_M_1_plus = pearsonr(S, SM_1_plus)[0]\n",
    "correlation_M_210 = pearsonr(S, SM_210)[0]\n",
    "correlation_M_2100 = pearsonr(S, SM_2100)[0]\n",
    "correlation_M_2300 = pearsonr(S, SM_2300)[0]\n",
    "\n",
    "print(\"Correlation with M_1:\", correlation_M_1)\n",
    "print(\"Correlation with M1+:\", correlation_M_1_plus)\n",
    "print(\"Correlation with M_210:\", correlation_M_210)\n",
    "print(\"Correlation with M_2100:\", correlation_M_2100)\n",
    "print(\"Correlation with M_2300:\", correlation_M_2300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
